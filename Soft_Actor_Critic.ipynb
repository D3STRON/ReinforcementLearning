{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benelot/pybullet-gym.git\n",
        "!cd pybullet-gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_T_U_1G-3Ki",
        "outputId": "9a6e9b6c-9f15-4d42-e1c1-46ae37720953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pybullet-gym'...\n",
            "remote: Enumerating objects: 804, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 804 (delta 21), reused 44 (delta 17), pack-reused 750\u001b[K\n",
            "Receiving objects: 100% (804/804), 19.31 MiB | 8.17 MiB/s, done.\n",
            "Resolving deltas: 100% (437/437), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd pybullet-gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhGP1r2M-9Qb",
        "outputId": "19492a1e-04f8-451e-a228-36f21526dfd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pybullet-gym\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFoJL_oq_F5r",
        "outputId": "96ee0977-c3c3-4e5d-c2ef-fdb7073aee9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/pybullet-gym\n",
            "Collecting pybullet>=1.7.8\n",
            "  Downloading pybullet-3.2.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (91.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 91.7 MB 101 kB/s \n",
            "\u001b[?25hInstalling collected packages: pybullet, pybulletgym\n",
            "  Running setup.py develop for pybulletgym\n",
            "Successfully installed pybullet-3.2.5 pybulletgym-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[box2d]\n",
        "import gym\n",
        "import pybulletgym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjAoWaH8_QqZ",
        "outputId": "f56a222e-d274-4a2f-ca9e-60914fefeaa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (4.13.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[box2d]) (1.21.6)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 130 kB/s \n",
            "\u001b[?25hCollecting box2d-py==2.3.5\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[K     |████████████████████████████████| 374 kB 74.6 MB/s \n",
            "\u001b[?25hCollecting swig==4.*\n",
            "  Downloading swig-4.1.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[box2d]) (3.10.0)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "Installing collected packages: swig, pygame, box2d-py\n",
            "    Running setup.py install for box2d-py ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: box2d-py was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0 swig-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpHfwlaoispX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch as T\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#import pybullet_envs\n",
        "from torch.distributions.normal import Normal\n",
        "import tqdm\n",
        "import random\n",
        "#import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRPWlkemjGcq"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(x, scores):\n",
        "    running_avg = np.zeros(len(scores))\n",
        "    for i in range(len(running_avg)):\n",
        "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
        "    plt.plot(x, running_avg)\n",
        "    plt.title('Running average of previous 1000 scores')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9O9QfPEjVqd"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size, input_shape, n_actions):\n",
        "        self.mem_size = max_size\n",
        "        self.mem_cntr = 0\n",
        "        self.state_memory = np.zeros((self.mem_size, *input_shape))\n",
        "        self.new_state_memory = np.zeros((self.mem_size, *input_shape))\n",
        "        self.action_memory = np.zeros((self.mem_size, n_actions))\n",
        "        self.reward_memory = np.zeros(self.mem_size)\n",
        "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
        "\n",
        "    def store_transition(self, state, action, reward, state_, done):\n",
        "        index = self.mem_cntr % self.mem_size\n",
        "\n",
        "        self.state_memory[index] = state\n",
        "        self.new_state_memory[index] = state_\n",
        "        self.action_memory[index] = action\n",
        "        self.reward_memory[index] = reward\n",
        "        self.terminal_memory[index] = done\n",
        "\n",
        "        self.mem_cntr += 1\n",
        "\n",
        "    def sample_buffer(self, batch_size):\n",
        "        max_mem = min(self.mem_cntr, self.mem_size)\n",
        "\n",
        "        batch = np.random.choice(max_mem, batch_size)\n",
        "\n",
        "        states = self.state_memory[batch]\n",
        "        states_ = self.new_state_memory[batch]\n",
        "        actions = self.action_memory[batch]\n",
        "        rewards = self.reward_memory[batch]\n",
        "        dones = self.terminal_memory[batch]\n",
        "\n",
        "        return states, actions, rewards, states_, dones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH8UMcANjZ-E"
      },
      "outputs": [],
      "source": [
        "class CriticNetwork(nn.Module):\n",
        "    def __init__(self, beta, input_dims, n_actions, fc1_dims=256, fc2_dims = 256,\n",
        "                name='critic'):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "        self.input_dims = input_dims\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.n_actions= n_actions\n",
        "        self.name = name\n",
        "        \n",
        "        self.fc1 = nn.Linear(self.input_dims[0]+ n_actions, self.fc1_dims)\n",
        "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
        "        self.q = nn.Linear(self.fc2_dims, 1)\n",
        "        \n",
        "        self.optimizer = optim.Adam(self.parameters(), lr= beta)\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        self.to(self.device)\n",
        "        \n",
        "    def forward(self, state, action):\n",
        "        action_value = self.fc1(T.cat([state,action], dim=1))\n",
        "        action_value = F.relu(action_value)\n",
        "        action_value = self.fc2(action_value)\n",
        "        action_value = F.relu(action_value)\n",
        "        \n",
        "        q = self.q(action_value)\n",
        "        \n",
        "        return q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr1Ld0lfjicL"
      },
      "outputs": [],
      "source": [
        "class ValueNetwork(nn.Module):\n",
        "    def __init__(self, beta, input_dims, fc1_dims=256, fc2_dims = 256\n",
        "                , name='value'):\n",
        "        super(ValueNetwork, self).__init__()\n",
        "        self.input_dims = input_dims\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.name = name\n",
        "        \n",
        "        self.fc1 = nn .Linear(*self.input_dims, self.fc1_dims)\n",
        "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
        "        self.v = nn.Linear(self.fc2_dims, 1)\n",
        "        \n",
        "        self.optimizer = optim.Adam(self.parameters(), lr= beta)\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "        print(self.device)\n",
        "        \n",
        "        self.to(self.device)\n",
        "    \n",
        "    def forward(self, state):\n",
        "        action_value = self.fc1(state)\n",
        "        action_value = F.relu(action_value)\n",
        "        action_value = self.fc2(action_value)\n",
        "        action_value = F.relu(action_value)\n",
        "        \n",
        "        v = self.v(action_value)\n",
        "        \n",
        "        return v "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD-s22E1jjEf"
      },
      "outputs": [],
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "    def __init__(self, beta, input_dims, max_action, fc1_dims=256, fc2_dims = 256,\n",
        "                n_actions=2, name='value'):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "        self.input_dims = input_dims\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.n_actions = n_actions\n",
        "        self.name = name\n",
        "        self.max_action = max_action\n",
        "        self.reparam_noise = 1e-6\n",
        "        \n",
        "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
        "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
        "        self.mu = nn.Linear(self.fc2_dims, self.n_actions)\n",
        "        self.sigma = nn.Linear(self.fc2_dims, self.n_actions)\n",
        "        \n",
        "        self.optimizer = optim.Adam(self.parameters(), lr= beta)\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        self.to(self.device)\n",
        "        \n",
        "    def forward(self, state):\n",
        "        prob = self.fc1(state)\n",
        "        prob = F.relu(prob)\n",
        "        prob = self.fc2(prob)\n",
        "        prob = F.relu(prob)\n",
        "        \n",
        "        mu = self.mu(prob)\n",
        "        sigma = self.sigma(prob)\n",
        "        # Limits the deviation of the actions distribution to a certain limit\n",
        "        sigma = T.clamp(sigma, min=self.reparam_noise, max=1)\n",
        "        \n",
        "        return mu, sigma\n",
        "    \n",
        "    def sample_normal(self, state, reparameterize = True):\n",
        "        state = state.float()\n",
        "        mu, sigma = self.forward(state)\n",
        "        probabilities = Normal(mu, sigma)\n",
        "        \n",
        "        if reparameterize:\n",
        "            #Actions seleted from a noise probability distribution\n",
        "            actions = probabilities.rsample()\n",
        "        else:\n",
        "            #Actions selected from a normal probability distribution\n",
        "            actions = probabilities.sample()\n",
        "            \n",
        "        action = T.tanh(actions)*T.tensor(self.max_action).to(self.device)\n",
        "        log_probs = probabilities.log_prob(actions)\n",
        "        log_probs -= T.log(1-action.pow(2)+self.reparam_noise)\n",
        "        log_probs = log_probs.sum(1, keepdim=True)\n",
        "\n",
        "        return action, log_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83xkaTtijjyh"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    def __init__(self, alpha=0.0003, beta=0.0003, input_dims=[8],\n",
        "            env=None, gamma=0.99, n_actions=2, max_size=1000000, tau=0.005,\n",
        "            layer1_size=256, layer2_size=256, batch_size=256, reward_scale=2):\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "        self.memory = ReplayBuffer(max_size, input_dims, n_actions)\n",
        "        self.batch_size = batch_size\n",
        "        self.n_actions = n_actions\n",
        "        \n",
        "        self.actor = ActorNetwork(alpha, input_dims, n_actions=n_actions,\n",
        "                                 name='actor', max_action= env.action_space.high)\n",
        "        self.critic_1 = CriticNetwork(beta, input_dims, n_actions=n_actions,\n",
        "                                     name=\"critic_1\")\n",
        "        self.critic_2 = CriticNetwork(beta, input_dims, n_actions=n_actions,\n",
        "                                     name=\"critic_2\")\n",
        "        self.value = ValueNetwork(beta, input_dims, name='value')\n",
        "        self.target_value = ValueNetwork(beta, input_dims, name='target_value')\n",
        "        \n",
        "        self.scale =reward_scale\n",
        "        self.update_network_parameters(tau=1)\n",
        "        \n",
        "    def choose_action(self, observation):\n",
        "        state = T.tensor([observation]).to(self.actor.device)\n",
        "        actions, _ = self.actor.sample_normal(state, reparameterize= False)\n",
        "        \n",
        "        return actions.cpu().detach().numpy()[0]\n",
        "    \n",
        "    def remember(self, state, action, reward, new_state, done):\n",
        "        self.memory.store_transition(state, action, reward, new_state, done)\n",
        "        \n",
        "    def update_network_parameters(self, tau=None):\n",
        "        if tau is None:\n",
        "            tau = self.tau\n",
        "\n",
        "        target_value_params = self.target_value.named_parameters()\n",
        "        value_params = self.value.named_parameters()\n",
        "\n",
        "        target_value_state_dict = dict(target_value_params)\n",
        "        value_state_dict = dict(value_params)\n",
        "\n",
        "        for name in value_state_dict:\n",
        "            value_state_dict[name] = tau*value_state_dict[name].clone() + \\\n",
        "                    (1-tau)*target_value_state_dict[name].clone()\n",
        "\n",
        "        self.target_value.load_state_dict(value_state_dict)\n",
        "    \n",
        "    def learn(self):\n",
        "        if self.memory.mem_cntr < self.batch_size:\n",
        "            return\n",
        "\n",
        "        state, action, reward, new_state, done = \\\n",
        "                self.memory.sample_buffer(self.batch_size)\n",
        "\n",
        "        reward = T.tensor(reward, dtype=T.float).to(self.actor.device)\n",
        "        done = T.tensor(done).to(self.actor.device)\n",
        "        state_ = T.tensor(new_state, dtype=T.float).to(self.actor.device)\n",
        "        state = T.tensor(state, dtype=T.float).to(self.actor.device)\n",
        "        action = T.tensor(action, dtype=T.float).to(self.actor.device)\n",
        "\n",
        "        value = self.value(state).view(-1)\n",
        "        value_ = self.target_value(state_).view(-1)\n",
        "        value_[done] = 0.0\n",
        "\n",
        "        actions, log_probs = self.actor.sample_normal(state, reparameterize=False)\n",
        "        log_probs = log_probs.view(-1)\n",
        "        q1_new_policy = self.critic_1.forward(state, actions)\n",
        "        q2_new_policy = self.critic_2.forward(state, actions)\n",
        "        critic_value = T.min(q1_new_policy, q2_new_policy)\n",
        "        critic_value = critic_value.view(-1)\n",
        "\n",
        "        self.value.optimizer.zero_grad()\n",
        "        value_target = critic_value - log_probs\n",
        "        value_loss = 0.5 * F.mse_loss(value, value_target)\n",
        "        value_loss.backward(retain_graph=True)\n",
        "        self.value.optimizer.step()\n",
        "\n",
        "        actions, log_probs = self.actor.sample_normal(state, reparameterize=True)\n",
        "        log_probs = log_probs.view(-1)\n",
        "        q1_new_policy = self.critic_1.forward(state, actions)\n",
        "        q2_new_policy = self.critic_2.forward(state, actions)\n",
        "        critic_value = T.min(q1_new_policy, q2_new_policy)\n",
        "        critic_value = critic_value.view(-1)\n",
        "        \n",
        "        actor_loss = log_probs - critic_value\n",
        "        actor_loss = T.mean(actor_loss)\n",
        "        self.actor.optimizer.zero_grad()\n",
        "        actor_loss.backward(retain_graph=True)\n",
        "        self.actor.optimizer.step()\n",
        "\n",
        "        self.critic_1.optimizer.zero_grad()\n",
        "        self.critic_2.optimizer.zero_grad()\n",
        "        q_hat = self.scale*reward + self.gamma*value_\n",
        "        q1_old_policy = self.critic_1.forward(state, action).view(-1)\n",
        "        q2_old_policy = self.critic_2.forward(state, action).view(-1)\n",
        "        critic_1_loss = 0.5 * F.mse_loss(q1_old_policy, q_hat)\n",
        "        critic_2_loss = 0.5 * F.mse_loss(q2_old_policy, q_hat)\n",
        "\n",
        "        critic_loss = critic_1_loss + critic_2_loss\n",
        "        critic_loss.backward()\n",
        "        self.critic_1.optimizer.step()\n",
        "        self.critic_2.optimizer.step()\n",
        "\n",
        "        self.update_network_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "KkoMFzZCktWB",
        "outputId": "66090529-e378-4dba-a212-65a68ceb251d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a185debd8fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LunarLanderContinuous-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m agent = Agent(input_dims=env.observation_space.shape, env=env,\n\u001b[1;32m      4\u001b[0m         n_actions=env.action_space.shape[0])\n\u001b[1;32m      5\u001b[0m \u001b[0mn_games\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
          ]
        }
      ],
      "source": [
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "\n",
        "agent = Agent(input_dims=env.observation_space.shape, env=env,\n",
        "        n_actions=env.action_space.shape[0])\n",
        "n_games = 1000\n",
        "# uncomment this line and do a mkdir tmp && mkdir video if you want to\n",
        "# record video of the agent playing the game.\n",
        "#env = wrappers.Monitor(env, 'tmp/video', video_callable=lambda episode_id: True, force=True)\n",
        "# filename = 'inverted_pendulum.png'\n",
        "\n",
        "# figure_file = 'plots/' + filename\n",
        "\n",
        "best_score = env.reward_range[0]\n",
        "score_history = []\n",
        "load_checkpoint = False\n",
        "\n",
        "# if load_checkpoint:\n",
        "#     agent.load_models()\n",
        "#     env.render(mode='human')\n",
        "\n",
        "for i in range(n_games):\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        action = agent.choose_action(observation)\n",
        "        observation_, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "        agent.remember(observation, action, reward, observation_, done)\n",
        "        if not load_checkpoint:\n",
        "            agent.learn()\n",
        "        observation = observation_\n",
        "    score_history.append(score)\n",
        "    avg_score = np.mean(score_history[-100:])\n",
        "\n",
        "    if avg_score > best_score:\n",
        "        best_score = avg_score\n",
        "#         if not load_checkpoint:\n",
        "#             agent.save_models()\n",
        "\n",
        "    print('episode ', i, 'score %.1f' % score, 'avg_score %.1f' % avg_score)\n",
        "\n",
        "if not load_checkpoint:\n",
        "    x = [i+1 for i in range(n_games)]\n",
        "    plot_learning_curve(x, score_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "QIuEZeTW-WEa",
        "outputId": "4c100102-7ce9-490c-cab6-c0029bd50e14"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-00691dafd8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HalfCheetahPyBulletEnv-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m agent = Agent(input_dims=env.observation_space.shape, env=env,\n\u001b[1;32m      4\u001b[0m         n_actions=env.action_space.shape[0])\n\u001b[1;32m      5\u001b[0m \u001b[0mn_games\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
          ]
        }
      ],
      "source": [
        "env = gym.make('HalfCheetahPyBulletEnv-v0')\n",
        "\n",
        "agent = Agent(input_dims=env.observation_space.shape, env=env,\n",
        "        n_actions=env.action_space.shape[0])\n",
        "n_games = 1000\n",
        "# uncomment this line and do a mkdir tmp && mkdir video if you want to\n",
        "# record video of the agent playing the game.\n",
        "#env = wrappers.Monitor(env, 'tmp/video', video_callable=lambda episode_id: True, force=True)\n",
        "# filename = 'inverted_pendulum.png'\n",
        "\n",
        "# figure_file = 'plots/' + filename\n",
        "\n",
        "best_score = env.reward_range[0]\n",
        "score_history = []\n",
        "load_checkpoint = False\n",
        "\n",
        "# if load_checkpoint:\n",
        "#     agent.load_models()\n",
        "#     env.render(mode='human')\n",
        "\n",
        "for i in range(n_games):\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        action = agent.choose_action(observation)\n",
        "        observation_, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "        agent.remember(observation, action, reward, observation_, done)\n",
        "        if not load_checkpoint:\n",
        "            agent.learn()\n",
        "        observation = observation_\n",
        "    score_history.append(score)\n",
        "    avg_score = np.mean(score_history[-100:])\n",
        "\n",
        "    if avg_score > best_score:\n",
        "        best_score = avg_score\n",
        "#         if not load_checkpoint:\n",
        "#             agent.save_models()\n",
        "\n",
        "    print('episode ', i, 'score %.1f' % score, 'avg_score %.1f' % avg_score)\n",
        "\n",
        "if not load_checkpoint:\n",
        "    x = [i+1 for i in range(n_games)]\n",
        "    plot_learning_curve(x, score_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frE27wEn-m_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a57388d0-06de-4565-fd99-eac1a9589e88"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w6mIlFAhOMNA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}